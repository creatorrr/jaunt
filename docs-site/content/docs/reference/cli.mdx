---
title: CLI
description: "Commands, flags, and exit codes."
---

For a guided, end-to-end introduction, start with [Quickstart](/docs/quickstart).

Entry point: `jaunt = "jaunt.cli:main"` (see `pyproject.toml` in the repo root).

## Init

Create a starter `jaunt.toml` in the target directory:

```bash
uv run jaunt init
uv run jaunt init --root /tmp/myproj
uv run jaunt init --force
uv run jaunt init --json
```

## Build

Generate implementation modules for `@jaunt.magic` specs:

```bash
uv run jaunt build
uv run jaunt build --force
uv run jaunt build --jobs 16
uv run jaunt build --target my_app.specs
uv run jaunt build --no-infer-deps
uv run jaunt build --json
```

## Test

Generate tests for `@jaunt.test` specs and run pytest:

```bash
uv run jaunt test
uv run jaunt test --no-build
uv run jaunt test --no-run
uv run jaunt test --pytest-args=-k --pytest-args email
uv run jaunt test --json
```

## Eval

Run the built-in eval suite against one provider/model or compare multiple.

```bash
uv run jaunt eval
uv run jaunt eval --provider anthropic --model claude-sonnet-4-5-20250929
uv run jaunt eval --compare openai:gpt-5.2 anthropic:claude-haiku-4-5
uv run jaunt eval --json
```

## Status

Show stale/fresh modules:

```bash
uv run jaunt status
uv run jaunt status --target my_app.specs
uv run jaunt status --json
```

## Clean

Remove generated directories under configured source/test roots:

```bash
uv run jaunt clean
uv run jaunt clean --dry-run
uv run jaunt clean --json
```

## Watch

Watch source/test roots and rebuild on relevant `.py` changes:

```bash
uv run jaunt watch
uv run jaunt watch --test
uv run jaunt watch --json
```

When `--json` is enabled, watch emits one JSON object per rebuild cycle (the watch envelope), not nested build/test JSON documents.

## MCP

Start the stdio MCP server:

```bash
uv run jaunt mcp serve
uv run jaunt mcp serve --root /path/to/project
```

`mcp` requires the optional dependency: `pip install jaunt[mcp]`.

## Common Flags

- `--root /path/to/project`: override project discovery (otherwise Jaunt searches upward for `jaunt.toml`).
- `--config /path/to/jaunt.toml`: override config path.
- `--target MODULE[:QUALNAME]`: restrict work to one or more modules (currently module-level; `:QUALNAME` is ignored for filtering).
- `--no-infer-deps`: disable best-effort dependency inference (explicit `deps=` still applies).
- `--json`: emit structured JSON output for agent/CI workflows.

## Exit Codes

- `0`: success
- `2`: config/discovery/dependency-cycle errors
- `3`: generation errors (LLM/backend/validation/import)
- `4`: pytest failure (only when `jaunt test` actually runs pytest)

Note: `jaunt test` runs pytest only on the generated test files it just wrote (not the entire suite). Run `pytest` separately for a full test run.

## Eval Results Snapshot (2026-02-15 UTC)

The table below captures the eval runs executed during provider bring-up and reasoning-control testing.

| Run (UTC) | Mode | Target | Reasoning | Passed | Failed | Skipped | Total | Notes |
| --- | --- | --- | --- | ---:| ---:| ---:| ---:| --- |
| 2026-02-15T21-34-58Z | single | `cerebras:gpt-oss-120b` | none | 0 | 10 | 0 | 10 | Missing `cerebras-cloud-sdk` dependency |
| 2026-02-15T21-35-17Z | single | `cerebras:gpt-oss-120b` | none | 0 | 10 | 0 | 10 | Cerebras `402 payment_required` quota/billing error |
| 2026-02-15T21-36-54Z | single | `cerebras:gpt-oss-120b` | none | 10 | 0 | 0 | 10 | All eval cases passed |
| 2026-02-15T22-01-24Z-custom-compare | compare | `cerebras:gpt-oss-120b` | low | 10 | 0 | 0 | 10 | All eval cases passed |
| 2026-02-15T22-01-24Z-custom-compare | compare | `openai:gpt-5.2` | none | 10 | 0 | 0 | 10 | All eval cases passed |
| 2026-02-15T22-01-24Z-custom-compare | compare | `anthropic:opus-4.6` | none | 0 | 10 | 0 | 10 | Anthropic `404 not_found_error` for model name |
| 2026-02-15T22-04-19Z-custom-compare | compare | `cerebras:gpt-oss-120b` | low | 10 | 0 | 0 | 10 | All eval cases passed |
| 2026-02-15T22-04-19Z-custom-compare | compare | `openai:gpt-5.2` | none | 10 | 0 | 0 | 10 | All eval cases passed |
| 2026-02-15T22-04-19Z-custom-compare | compare | `anthropic:claude-haiku-4-5` | none | 9 | 1 | 0 | 10 | One assertion failure (`example_slugify_smoke`) |

Raw artifacts are under `examples/expr_eval/.jaunt/evals/` in the repository.

Next: [Configuration](/docs/reference/config).
